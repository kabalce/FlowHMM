{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import json\n",
    "import datetime\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "from ssm.util import find_permutation\n",
    "from pathlib import Path\n",
    "from hmmlearn import hmm\n",
    "\n",
    "from theoretical_experiment.visual_tools import plot_HMM2, plot_Qs, plot_metric, plot_HMM3\n",
    "\n",
    "PROJECT_PATH = Path(__file__).parent\n",
    "# import sys\n",
    "# sys.path.insert(1, PROJECT_PATH)\n",
    "from torchHMM.utils.utils import total_variance_dist\n",
    "from torchHMM.model.FlowHMM import FlowHMM, DISCRETIZATION_TECHNIQUES\n",
    "\n",
    "LEARNING_ALGORITHMS = [\"em\", \"cooc\"]\n",
    "T = 10000\n",
    "np.random.seed(2023)\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "wandb_project_name = f\"2_FlowHMM_{datetime.datetime.now().strftime('%Y-%m-%d-%H-%M')}\"\n",
    "\n",
    "def Q_from_params(model_):\n",
    "    \"\"\"\n",
    "    Calculate Q from model parameters\n",
    "    \"\"\"\n",
    "    if hasattr(model_, 'emissionprob_'):\n",
    "        return Q_from_params_d(model_)\n",
    "\n",
    "    S_ = model_.transmat_ * model_.startprob_[:, np.newaxis]\n",
    "    distributions_ = [\n",
    "        scipy.stats.multivariate_normal(model_.means_[i], model_.covars_[i])\n",
    "        for i in range(model_.n_components)\n",
    "    ]\n",
    "\n",
    "    B_ = np.concatenate(\n",
    "        [dist.pdf(model_.nodes.T).reshape(1, -1) for dist in distributions_],\n",
    "        axis=0,\n",
    "    )\n",
    "    B_ = B_ / B_.sum(1)[:, np.newaxis]\n",
    "    return B_.T @ S_ @ B_\n",
    "\n",
    "\n",
    "def Q_from_params_d(model_):\n",
    "    \"\"\"\n",
    "    Calculate Q from model parameters\n",
    "    \"\"\"\n",
    "    S_ = model_.transmat_ * model_.startprob_[:, np.newaxis]\n",
    "    B_ = model_.emissionprob_\n",
    "    return B_.T @ S_ @ B_\n",
    "\n",
    "\n",
    "def init_model(discretize_meth, X_train_, n):\n",
    "    \"\"\"\n",
    "    Init DiscreteHMM with parameters from true model\n",
    "    \"\"\"\n",
    "    model_ = FlowHMM(\n",
    "        discretize_meth,\n",
    "        n,\n",
    "        learning_alg=\"cooc\",\n",
    "        verbose=True,\n",
    "        params=\"ste\",\n",
    "        init_params=\"ste\",\n",
    "        optim_params=dict(max_epoch=50000, lr=0.1, weight_decay=0),\n",
    "        n_iter=100,\n",
    "    )\n",
    "\n",
    "    model_._init(X_train_)\n",
    "    model_.provide_nodes(X_train_, False)\n",
    "    return model_\n",
    "\n",
    "\n",
    "def list_grid_size():\n",
    "    return [\n",
    "        # 2**2,\n",
    "        2**4,\n",
    "        2**6,\n",
    "        # 2**8\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "def kl_divergence(p_, q_):\n",
    "    p = p_.reshape(-1) + 1e-10\n",
    "    p /= p.sum()\n",
    "    q = q_.reshape(-1) + 1e-10\n",
    "    q /= q.sum()\n",
    "    return np.sum(p * np.log2(p / q))\n",
    "\n",
    "\n",
    "def accuracy(Z_hat, Z_):\n",
    "    perm = find_permutation(np.concatenate([Z_hat, np.arange(max(Z_))]),\n",
    "                            np.concatenate([Z_, np.arange(max(Z_))]))\n",
    "    return (perm[Z_hat] == Z_).mean()\n",
    "\n",
    "def score_model(model_, X_, Z_, Q_gt, info):\n",
    "    ll = model.score(X_, np.array(X_.shape[0]))\n",
    "    acc = accuracy(model_.predict(X_, np.array(X_.shape[0])), Z_)\n",
    "    if Q_gt is not None:\n",
    "        Q = Q_from_params(model_)\n",
    "        kl = kl_divergence(Q, Q_gt)\n",
    "        d_tv = total_variance_dist(Q, Q_gt)\n",
    "    else:\n",
    "        kl = None\n",
    "        d_tv = None\n",
    "    return {'kl': kl, 'll': ll, 'acc': acc, 'd_tv': d_tv, **info}\n",
    "\n",
    "results_path = f\"{PROJECT_PATH}/thesis/\"\n",
    "Path(results_path).mkdir(exist_ok=True, parents=True)\n",
    "grid_sizes = list_grid_size()\n",
    "\n",
    "\n",
    "if True:\n",
    "    X_train, Z_train = make_moons(T, random_state=2023, noise=0.05)\n",
    "    X_test, Z_test = make_moons(T // 10, random_state=2022, noise=0.05)\n",
    "\n",
    "    results = list()\n",
    "\n",
    "    for discretize_meth in DISCRETIZATION_TECHNIQUES[-1:]:\n",
    "        for n in grid_sizes[-1:]:\n",
    "            model = init_model(discretize_meth, X_train, n)\n",
    "\n",
    "            for max_epoch, lr, lambda_ in itertools.product([1000],  [0.01], [0, 1]):\n",
    "\n",
    "                for _ in tqdm(range(1)): # As we work with random methods, the initialization and  the discretization differ in runs\n",
    "                    run = None\n",
    "                    run = wandb.init(\n",
    "                       project=wandb_project_name,\n",
    "                       name=f\"ex_2_{discretize_meth}_{n}_{max_epoch}_{lr}\",\n",
    "                       notes=\"FlowHMM with co-occurrence-based learning schema logger\",\n",
    "                       dir=f'{PROJECT_PATH}/'\n",
    "                    )\n",
    "                    wandb.config = dict(max_epoch=max_epoch, lr=lr, weight_decay=0, disc=discretize_meth, n=n)\n",
    "                    model = FlowHMM(\n",
    "                        discretization_method=discretize_meth,\n",
    "                        no_nodes=n,\n",
    "                        n_components=2,\n",
    "                        learning_alg=\"cooc\",\n",
    "                        verbose=True,\n",
    "                        params=\"ste\",\n",
    "                        init_params=\"ste\",\n",
    "                        optim_params=dict(max_epoch=20, lr=lr, weight_decay=0, run=run),\n",
    "                        n_iter=100,\n",
    "                        optimizer=\"Adam\",\n",
    "                    )\n",
    "\n",
    "                    for i in range(50):\n",
    "                        plot_HMM3(X_test, model,\n",
    "                                  path=f\"{results_path}/flow_on_moons_{i}_penalty={lambda_}.png\")\n",
    "                        plot_Qs(Q_from_params(model), model._cooccurence(model.discretize(X_train, True)),\n",
    "                                f\"{results_path}/Q_moons_{i}_penalty={lambda_}.png\")\n",
    "                        results.append(\n",
    "                            score_model(model, X_test, Z_test, model._cooccurence(model.discretize(X_train, True)),\n",
    "                                        dict(i=i * 20, penalty=lambda_)))\n",
    "                        model.fit(X_train, lambda_=lambda_)\n",
    "\n",
    "                    wandb.finish()\n",
    "\n",
    "\n",
    "\n",
    "                with open(\n",
    "                    f\"{results_path}/single_run.json\",\n",
    "                    \"w\",\n",
    "                ) as f:\n",
    "                    json.dump(results, f, indent=4)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
