{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "np.random.seed(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "size = 50\n",
    "X = np.random.normal(0, 1, size = size)\n",
    "lim = np.abs(X).max() + 0.2\n",
    "xs = np.arange(1000) / 500 * lim - lim"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42cc76d2d2d5ccb8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "M = 10\n",
    "grid = np.arange(M) / M * 2 * lim - lim + 0.25"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd6c12c395a74962"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from theoretical_experiment.visual_tools import colors"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "799bb33eb19cf149"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.style.available"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "697f76c954d62c73"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-v0_8-white')\n",
    "# plt.style.use('classic')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f21cf0e7d85ca28"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, sharey=True, figsize=(15, 4))\n",
    "plt.xlim([-lim, lim])\n",
    "\n",
    "ax[0].scatter(X, np.zeros(size), marker='x')\n",
    "ax[0].plot(xs, stats.norm.pdf(xs))\n",
    "ax[0].title.set_text('Continuous data and density function')\n",
    "ax[0].title.set_size(16)\n",
    "\n",
    "cdfs = [0, *[stats.norm.cdf((grid[i] + grid[i+1])/2) for i in range(len(grid)-1)], 1]\n",
    "ax[1].scatter(X, np.zeros(size), marker='x')\n",
    "ax[1].plot(xs, stats.norm.pdf(xs))\n",
    "ax[1].scatter(grid, stats.norm.pdf(grid))\n",
    "# ax[1].xlim([-lim, lim])\n",
    "xmin, xmax = -lim, (grid[0] + grid[1]) / 2\n",
    "for i in range(len(grid) - 1):\n",
    "    ax[1].vlines([(grid[i] + grid[i+1]) / 2], 0, 0.42, linestyles='--', color='grey', alpha = 0.7)\n",
    "    ax[1].hlines([cdfs[i+1] - cdfs[i]], xmin, xmax, linestyles='--', color='grey', alpha = 0.7)\n",
    "    if i < len(grid) - 2:\n",
    "        xmin, xmax = xmax, (grid[i+1] + grid[i+2]) / 2\n",
    "    else:\n",
    "        xmin, xmax = xmax, lim\n",
    "ax[1].hlines(cdfs[-1] - cdfs[-2], xmin, xmax, linestyles='--', color='grey', alpha = 0.7)\n",
    "ax[1].title.set_text('Discrete values and real area probabilities')\n",
    "ax[1].title.set_size(16)\n",
    "\n",
    "xmin, xmax = -lim, (grid[0] + grid[1]) / 2\n",
    "normalizer = stats.norm.pdf(grid).sum()\n",
    "for i in range(len(grid)):\n",
    "    ax[2].hlines([cdfs[i+1] - cdfs[i]], xmin, xmax, linestyles='--', color='grey', alpha = 0.7)\n",
    "    indicators  = np.all(np.concatenate([(X < xmax).reshape(-1, 1),  (X >= xmin).reshape(-1, 1)], axis=1), axis=1)\n",
    "    ax[2].scatter(X[indicators], np.ones(indicators.sum()) * stats.norm.pdf(grid[i]) / normalizer, marker='x', color=colors[i])\n",
    "    ax[2].scatter(grid[i], stats.norm.pdf(grid[i]), color=colors[i])\n",
    "    if i < len(grid) - 1:\n",
    "        ax[2].vlines([(grid[i] + grid[i+1]) / 2], 0, 0.42, linestyles='--', color='grey', alpha = 0.7)\n",
    "    if i < len(grid) - 2:\n",
    "        xmin, xmax = xmax, (grid[i+1] + grid[i+2]) / 2\n",
    "    else:\n",
    "        xmin, xmax = xmax, lim\n",
    "ax[2].title.set_text('Discretized data with normalized mass function')\n",
    "ax[2].title.set_size(16)\n",
    "\n",
    "plt.suptitle('Discretization procedure on gaussian example', size=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('chapter4/discretization_image.eps', format='eps')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ffa1e0d803431553"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Estimation of $\\pi$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13a2029bdc8cae93"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.stats import qmc\n",
    "import numpy as np\n",
    "\n",
    "sample_size = 10\n",
    "\n",
    "sobol = qmc.Sobol(2).random(sample_size)\n",
    "halton = qmc.Halton(2).random(sample_size)\n",
    "latin = qmc.LatinHypercube(2).random(sample_size)\n",
    "uniform = np.random.uniform(size=(sample_size, 2))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23a2e78cb12faeef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def estimate_pi_2d(x):\n",
    "    return (x[:, 0] ** 2 + x[:, 1] ** 2 <= 1).mean() * 4 \n",
    "\n",
    "def estimate_pi_1d(x):\n",
    "    return (np.sqrt(1 - x**2)).mean() * 4 "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d84ae42e7310fc59"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(estimate_pi_2d(sobol))\n",
    "print(estimate_pi_2d(halton))\n",
    "print(estimate_pi_2d(latin))\n",
    "print(estimate_pi_2d(uniform))\n",
    "\n",
    "print(estimate_pi_1d(sobol))\n",
    "print(estimate_pi_1d(halton))\n",
    "print(estimate_pi_1d(latin))\n",
    "print(estimate_pi_1d(uniform))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5cfd344f419dcc23"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1D"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99bc1b33b28b6ba3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_size = 64\n",
    "\n",
    "sobol_res = []\n",
    "halton_res = []\n",
    "latin_res = []\n",
    "uniform_res = []\n",
    "grid_res = []\n",
    "\n",
    "np.random.seed(2023)\n",
    "\n",
    "for i in range(100):\n",
    "    sobol = qmc.Sobol(1).random(sample_size)\n",
    "    halton = qmc.Halton(1).random(sample_size)\n",
    "    latin = qmc.LatinHypercube(1).random(sample_size)\n",
    "    uniform = np.random.uniform(size=(sample_size, 1))\n",
    "    # grid = np.concatenate([np.concatenate([(np.arange(int(np.sqrt(sample_size))) + 0.5) / int(np.sqrt(sample_size)) for i in range(int(np.sqrt(sample_size)))]).reshape(-1, 1), np.concatenate([(np.ones(int(np.sqrt(sample_size))) * i + 0.5) / int(np.sqrt(sample_size)) for i in range(int(np.sqrt(sample_size)))]).reshape(-1, 1)], axis=1)\n",
    "    grid = np.arange(sample_size) / (sample_size - 1)\n",
    "    \n",
    "    sobol_res.append(estimate_pi_1d(sobol))\n",
    "    halton_res.append(estimate_pi_1d(halton))\n",
    "    latin_res.append(estimate_pi_1d(latin))\n",
    "    uniform_res.append(estimate_pi_1d(uniform))\n",
    "    grid_res.append(estimate_pi_1d(grid))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92f6ae8e0df4ff14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68be3e7f57a6756e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'QS': sobol_res, 'QH': halton_res, 'LH': latin_res, 'RU': uniform_res, 'OG': grid_res, }\n",
    "                    ).melt(None, None, 'sample', 'value')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6bf28a9597d53546"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.boxenplot(results, x='value', y='sample')\n",
    "plt.ylabel('')\n",
    "plt.vlines(np.pi, -.5, 4.5, colors=['black'], linestyles='--')\n",
    "plt.xlabel('$\\pi$ estimator')\n",
    "plt.title('$\\pi$ estimation boxplots')\n",
    "plt.tight_layout()\n",
    "plt.savefig('chapter4/pi_example_1d.eps', format='eps')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b51df6b4782d432"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def plot_circle1(x, technique, dim=1):\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.vlines(x, 0, np.sqrt(1 - x**2))\n",
    "    plt.plot(np.arange(1000) / 1000, np.sqrt(1 - (np.arange(1000) / 1000)**2))\n",
    "    plt.title(f'Estimate $\\pi$ with {dim}D points from {technique}')\n",
    "    plt.savefig(f'chapter4/{technique}_{dim}D_circle.eps', format='eps')\n",
    "    plt.show() \n",
    "    \n",
    "def plot_circle2(x, technique,  dim=2):\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.scatter(x[:, 0], x[:, 1], color=['blue' if x[i, 0]**2 + x[i, 1] ** 2 <= 1 else 'grey' for i in range(x.shape[0])])\n",
    "    plt.plot(np.arange(1000) / 1000, np.sqrt(1 - (np.arange(1000) / 1000)**2))\n",
    "    plt.title(f'Estimate $\\pi$ with {dim}D points from {technique}')\n",
    "    plt.savefig(f'chapter4/{technique}_{dim}D_circle.eps', format='eps')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2df0c179d32d4331"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_circle1(sobol, 'QS')\n",
    "plot_circle1(halton, 'QH')\n",
    "plot_circle1(latin, 'LH')\n",
    "plot_circle1(uniform, 'RU')\n",
    "plot_circle1(grid, 'OG')\n",
    "\n",
    "# technique = 'Integrate 1D Grid'\n",
    "# plt.figure(figsize=(4, 4))\n",
    "# plt.vlines(grid_1D[:, 0], 0,  grid_1D[:, 1])\n",
    "# plt.plot(np.arange(1000) / 1000, np.sqrt(1 - (np.arange(1000) / 1000)**2))\n",
    "# plt.title(f'Estimate $\\pi$ with points from {technique}')\n",
    "# plt.savefig(f'chapter4/{technique}_circle.eps', format='eps')\n",
    "# plt.show() \n",
    "# \n",
    "# technique = 'Integrate 1D Unifrom'\n",
    "# plt.figure(figsize=(4, 4))\n",
    "# plt.vlines(uniform_1D[:, 0], 0,  uniform_1D[:, 1])\n",
    "# plt.plot(np.arange(1000) / 1000, np.sqrt(1 - (np.arange(1000) / 1000)**2))\n",
    "# plt.title(f'Estimate $\\pi$ with points from {technique}')\n",
    "# plt.savefig(f'chapter4/{technique}_circle.eps', format='eps')\n",
    "# plt.show() "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ad50ea8baaf1e9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2D"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a35ea452630443"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_size = 256\n",
    "\n",
    "sobol_res = []\n",
    "halton_res = []\n",
    "latin_res = []\n",
    "uniform_res = []\n",
    "grid_res = []\n",
    "\n",
    "np.random.seed(2023)\n",
    "\n",
    "for i in range(100):\n",
    "    sobol = qmc.Sobol(2).random(sample_size)\n",
    "    halton = qmc.Halton(2).random(sample_size)\n",
    "    latin = qmc.LatinHypercube(2).random(sample_size)\n",
    "    uniform = np.random.uniform(size=(sample_size, 2))\n",
    "    grid = np.concatenate([np.concatenate([(np.arange(int(np.sqrt(sample_size)))) / int(np.sqrt(sample_size) - 1) for i in range(int(np.sqrt(sample_size)))]).reshape(-1, 1), np.concatenate([(np.ones(int(np.sqrt(sample_size))) * i) / int(np.sqrt(sample_size) -  1) for i in range(int(np.sqrt(sample_size)))]).reshape(-1, 1)], axis=1)\n",
    "    # grid = np.arange(sample_size) / (sample_size - 1)\n",
    "\n",
    "    sobol_res.append(estimate_pi_2d(sobol))\n",
    "    halton_res.append(estimate_pi_2d(halton))\n",
    "    latin_res.append(estimate_pi_2d(latin))\n",
    "    uniform_res.append(estimate_pi_2d(uniform))\n",
    "    grid_res.append(estimate_pi_2d(grid))\n",
    "\n",
    "results = pd.DataFrame({'QS': sobol_res, 'QH': halton_res, 'LH': latin_res, 'RU': uniform_res, 'OG': grid_res, }\n",
    "                       ).melt(None, None, 'sample', 'value')\n",
    "\n",
    "sns.boxenplot(results, x='value', y='sample')\n",
    "plt.ylabel('')\n",
    "plt.vlines(np.pi, -.5, 4.5, colors=['black'], linestyles='--')\n",
    "plt.xlabel('$\\pi$ estimator')\n",
    "plt.title('$\\pi$ estimation boxplots')\n",
    "plt.tight_layout()\n",
    "plt.savefig('chapter4/pi_example_2d.eps', format='eps')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def plot_circle(x, technique,  dim=2):\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.scatter(x[:, 0], x[:, 1], color=['blue' if x[i, 0]**2 + x[i, 1] ** 2 <= 1 else 'grey' for i in range(x.shape[0])])\n",
    "    plt.plot(np.arange(1000) / 1000, np.sqrt(1 - (np.arange(1000) / 1000)**2))\n",
    "    plt.title(f'Estimate $\\pi$ with {dim}D points from {technique}')\n",
    "    plt.savefig(f'chapter4/{technique}_{dim}D_circle.eps', format='eps')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_circle(sobol, 'QS')\n",
    "plot_circle(halton, 'QH')\n",
    "plot_circle(latin, 'LH')\n",
    "plot_circle(uniform, 'RU')\n",
    "plot_circle(grid, 'OG')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b5d1652d62915d6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Gaussian HMM - discretization example"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd1f32b446a903a0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "import array_to_latex as a2l\n",
    "from ssm.plots import gradient_cmap, white_to_color_cmap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import urllib\n",
    "import scipy\n",
    "from theoretical_experiment.visual_tools import colors"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79757bc8ae5331c2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "PROJECT_PATH = \"..\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import json\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "from ssm.util import find_permutation\n",
    "from pathlib import Path\n",
    "from hmmlearn import hmm\n",
    "\n",
    "from theoretical_experiment.visual_tools import plot_HMM, plot_Qs, plot_metric"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4a09395c2f853d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchHMM.utils.utils import total_variance_dist\n",
    "from torchHMM.model.GaussianHMM import DiscreteHMM, DISCRETIZATION_TECHNIQUES, HmmOptim\n",
    "\n",
    "LEARNING_ALGORITHMS = [\"em\", \"cooc\"]\n",
    "T = 10000\n",
    "np.random.seed(2023)\n",
    "\n",
    "\n",
    "def init_true_model():\n",
    "    true_model = hmm.GaussianHMM(n_components=3, covariance_type=\"full\")\n",
    "\n",
    "    true_model.startprob_ = np.array([0.6, 0.3, 0.1])\n",
    "    true_model.transmat_ = np.array([[0.7, 0.2, 0.1], [0.3, 0.5, 0.2], [0.3, 0.3, 0.4]])\n",
    "\n",
    "    true_model.means_ = np.array([[0.0, 0.0], [3.0, -3.0], [4.0, 3.0]])\n",
    "    true_model.covars_ = (\n",
    "        np.array(\n",
    "            [\n",
    "                [[1, -0.5], [-0.5, 1.2]],\n",
    "                [[0.6, -0.5], [-0.5, 1.2]],\n",
    "                [[1.5, 0.5], [0.5, 2.2]],\n",
    "            ]\n",
    "        )\n",
    "        * 0.8\n",
    "    )\n",
    "\n",
    "    true_model.n_features = 2\n",
    "\n",
    "    norm1 = multivariate_normal(true_model.means_[0], true_model.covars_[0])\n",
    "    norm2 = multivariate_normal(true_model.means_[1], true_model.covars_[1])\n",
    "    norm3 = multivariate_normal(true_model.means_[2], true_model.covars_[2])\n",
    "    norms = [norm1, norm2, norm3]\n",
    "\n",
    "    return true_model, norms\n",
    "\n",
    "\n",
    "def Q_from_params(model_):\n",
    "    \"\"\"\n",
    "    Calculate Q from model parameters\n",
    "    \"\"\"\n",
    "    S_ = model_.transmat_ * model_.startprob_[:, np.newaxis]\n",
    "    distributions_ = [\n",
    "        scipy.stats.multivariate_normal(model_.means_[i], model_.covars_[i])\n",
    "        for i in range(model_.n_components)\n",
    "    ]\n",
    "\n",
    "    B_ = np.concatenate(\n",
    "        [dist.pdf(model_.nodes.T).reshape(1, -1) for dist in distributions_],\n",
    "        axis=0,\n",
    "    )\n",
    "    B_ = B_ / B_.sum(1)[:, np.newaxis]\n",
    "    return B_.T @ S_ @ B_\n",
    "\n",
    "\n",
    "def init_model_with_params(discretize_meth, true_model_, X_train_, n):\n",
    "    \"\"\"\n",
    "    Init DiscreteHMM with parameters from true model\n",
    "    \"\"\"\n",
    "    model_ = DiscreteHMM(\n",
    "        discretize_meth,\n",
    "        n,\n",
    "        n_components=3,\n",
    "        learning_alg=\"cooc\",\n",
    "        verbose=True,\n",
    "        params=\"mct\",\n",
    "        init_params=\"\",\n",
    "        optim_params=dict(max_epoch=50000, lr=0.1, weight_decay=0),\n",
    "        n_iter=100,\n",
    "    )\n",
    "\n",
    "    model_.startprob_ = true_model_.startprob_\n",
    "    model_.transmat_ = true_model_.transmat_\n",
    "    model_.means_ = true_model_.means_\n",
    "    model_.covars_ = true_model_.covars_\n",
    "\n",
    "    model_._init(X_train_)\n",
    "    model_.provide_nodes(X_train_, False)\n",
    "    return model_\n",
    "\n",
    "\n",
    "def list_grid_size(n_=3):\n",
    "    return [\n",
    "        10,\n",
    "        int(np.ceil(0.5 * n_ * (1 + (2 * n_ - 1)**2))),\n",
    "        50,\n",
    "        int(np.ceil(np.sqrt(0.5 * n_ * (1 + (2 * n_ - 1)**2) * np.sqrt(T * n_ + 3**2)))),\n",
    "        100,\n",
    "        int(np.ceil(np.sqrt(T * n_ + n_**2))),\n",
    "        250,\n",
    "    ]\n",
    "\n",
    "\n",
    "def kl_divergence(p_, q_):\n",
    "    p = p_.reshape(-1) + 1e-10\n",
    "    p /= p.sum()\n",
    "    q = q_.reshape(-1) + 1e-10\n",
    "    q /= q.sum()\n",
    "    return np.sum(p * np.log2(p / q))\n",
    "\n",
    "\n",
    "def accuracy(Z_hat, Z_):\n",
    "    perm = find_permutation(np.concatenate([Z_hat, np.arange(max(Z_))]),\n",
    "                            np.concatenate([Z_, np.arange(max(Z_))]))\n",
    "    return (perm[Z_hat] == Z_).mean()\n",
    "\n",
    "def score_model(model_, X_, Z_, Q_gt, info):\n",
    "    ll = model.score(X_)\n",
    "    acc = accuracy(model_.predict(X_), Z_)\n",
    "    if Q_gt is not None:\n",
    "        Q = Q_from_params(model_)\n",
    "        kl = kl_divergence(Q, Q_gt)\n",
    "        d_tv = total_variance_dist(Q, Q_gt)\n",
    "    else:\n",
    "        kl = None\n",
    "        d_tv = None\n",
    "    return {'kl': kl, 'll': ll, 'acc': acc, 'd_tv': d_tv, **info}\n",
    "\n",
    "results_path = f\"{PROJECT_PATH}/theoretical_experiment/1_results\"\n",
    "Path(results_path).mkdir(exist_ok=True, parents=True)\n",
    "grid_sizes = list_grid_size()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a85b13acc1cd48d1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "T = 100\n",
    "true_model, _ = init_true_model()\n",
    "X, Z = true_model.sample(T)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5414f434260e50ef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n=16"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13feb5f1807ce764"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "title_strings = {'grid': 'OG',\n",
    "                                     'random': 'RO',\n",
    "                                     'latin_cube_u':  'LH',\n",
    "                                     'latin_cube_q': 'LH_q',\n",
    "                                     'sobol': 'QS',\n",
    "                 'uniform':'RU',\n",
    "                                     'halton': 'QH'}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8aff1d9fad48bc1f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "[colors[0]]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b51de2320aac03cf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import defaultdict as dd\n",
    "res = dd(list)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "np.random.seed(2023)\n",
    "for discretize_meth in DISCRETIZATION_TECHNIQUES:\n",
    "    for _ in range(100):\n",
    "        # print(discretize_meth)\n",
    "        model = init_model_with_params(discretize_meth, true_model, X, n)\n",
    "        Xd = model.discretize(X, np.array([X.shape[0]]))\n",
    "        Xd_c = model.nodes[:,  Xd.reshape(-1)].T\n",
    "        res[discretize_meth].append(true_model.score(Xd_c, np.array([X.shape[0]])))\n",
    "    \n",
    "    \"\"\"\n",
    "    Plot emission distribution and nodes\n",
    "    \"\"\"\n",
    "    norm1 = multivariate_normal(model.means_[0], model.covars_[0])\n",
    "    norm2 = multivariate_normal(model.means_[1], model.covars_[1])\n",
    "    norm3 = multivariate_normal(model.means_[2], model.covars_[2])\n",
    "    norms = [norm1, norm2, norm3]\n",
    "    \n",
    "    x1, y1 = X.min(axis=0) - .5\n",
    "    x2, y2 = X.max(axis=0) + .5\n",
    "    \n",
    "    XX, YY = np.meshgrid(np.linspace(x1, x2, 100), np.linspace(y1, y2, 100))\n",
    "    data = np.column_stack((XX.ravel(), YY.ravel()))\n",
    "    lls = np.concatenate([norm.pdf(data).reshape(-1, 1) for norm in norms], axis=1)\n",
    "    \n",
    "    plt.figure(figsize=(5, 5))\n",
    "    for k in range(model.n_components):\n",
    "        plt.contour(XX, YY, np.exp(lls[:, k]).reshape(XX.shape), cmap=white_to_color_cmap(sns.xkcd_palette(['grey'])[0]), levels=6)\n",
    "        \n",
    "    plt.scatter(model.nodes[0], model.nodes[1], marker='x', s=80, color=[colors[i*4] for i in range(model.no_nodes)])\n",
    "    plt.scatter(X[:, 0], X[:,  1],  marker='o', s=15, color=[colors[i*4] for i in Xd.reshape(-1)],  alpha=1)\n",
    "    plt.xlabel(\"$x_1$\")\n",
    "    plt.ylabel(\"$x_2$\")\n",
    "    plt.suptitle(\"True distributions, sample and nodes\", size=16)\n",
    "    if discretize_meth in title_strings.keys():\n",
    "        plt.title(f\"{title_strings[discretize_meth]} {n}\", size=14)\n",
    "    else:\n",
    "        plt.title(f\"{discretize_meth} {n}\", size=14)\n",
    "    plt.savefig(f'chapter4/gaussianHmm_discrete_example_{discretize_meth}.eps', format='eps')\n",
    "    plt.show()\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a0174c471963ba3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = (pd.DataFrame(res).rename(title_strings,  axis=1) * -1).melt(None, None, 'sample', 'value')\n",
    "sns.boxenplot(results, x='value', y='sample')\n",
    "plt.ylabel('')\n",
    "plt.vlines(true_model.score(X)* (-1), -.5, 6.5, colors=['black'], linestyles='--')\n",
    "plt.xlabel('negative log-likelihood')\n",
    "plt.title('Log-likelihood of discretized sequences')\n",
    "plt.xscale('log')\n",
    "plt.tight_layout()\n",
    "plt.savefig('chapter4/gaussianHMM_example.eps', format='eps')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d07f19fdadb84a4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 10D"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46d357180312ef35"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "means = [np.random.uniform(size=10)[np.newaxis, ] * 10 - 5 for _ in range(3)]\n",
    "def LU(a):\n",
    "    b = np.tril(a)\n",
    "    return b.T @ b\n",
    "covars = [LU(np.random.uniform(size=(10,  10)) + 0.1)[np.newaxis, ] for _ in range(3)]\n",
    "\n",
    "print(means)\n",
    "\n",
    "print(covars)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7e04f6361e0ef20"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def init_true_model():\n",
    "    true_model = hmm.GaussianHMM(n_components=3, covariance_type=\"full\")\n",
    "\n",
    "    true_model.startprob_ = np.array([0.6, 0.3, 0.1])\n",
    "    true_model.transmat_ = np.array([[0.7, 0.2, 0.1], [0.3, 0.5, 0.2], [0.3, 0.3, 0.4]])\n",
    "\n",
    "    true_model.means_ = np.concatenate(means)\n",
    "    true_model.covars_ = np.concatenate(covars)\n",
    "\n",
    "    true_model.n_features = 10\n",
    "\n",
    "    norm1 = multivariate_normal(true_model.means_[0], true_model.covars_[0])\n",
    "    norm2 = multivariate_normal(true_model.means_[1], true_model.covars_[1])\n",
    "    norm3 = multivariate_normal(true_model.means_[2], true_model.covars_[2])\n",
    "    norms = [norm1, norm2, norm3]\n",
    "\n",
    "    return true_model, norms"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b4957e40298237c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ff3246d2af0987d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.random.seed(2023)\n",
    "T = 2000\n",
    "true_model, _ = init_true_model()\n",
    "X, Z = true_model.sample(T)\n",
    "\n",
    "pca = PCA(2).fit(X)\n",
    "\n",
    "X2 = pca.transform(X)\n",
    "\n",
    "n = 2 ** 10\n",
    "\n",
    "title_strings = {'grid': 'OG',\n",
    "                 'random': 'RO',\n",
    "                 'latin_cube_u': 'LH',\n",
    "                 'latin_cube_q': 'LH_q',\n",
    "                 'sobol': 'QS',\n",
    "                 'uniform': 'RU',\n",
    "                 'halton': 'QH'}\n",
    "\n",
    "res = dd(list)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "np.random.seed(2023)\n",
    "\n",
    "norm1 = multivariate_normal(true_model.means_[0], true_model.covars_[0])\n",
    "norm2 = multivariate_normal(true_model.means_[1], true_model.covars_[1])\n",
    "norm3 = multivariate_normal(true_model.means_[2], true_model.covars_[2])\n",
    "norms = [norm1, norm2, norm3]\n",
    "\n",
    "x1, y1 = X2.min(axis=0) - .5\n",
    "x2, y2 = X2.max(axis=0) + .5\n",
    "\n",
    "XX, YY = np.meshgrid(np.linspace(x1, x2, 100), np.linspace(y1, y2, 100))\n",
    "data = np.column_stack((XX.ravel(), YY.ravel()))\n",
    "lls = np.concatenate([norm.pdf(pca.inverse_transform(data)).reshape(-1, 1) for norm in norms], axis=1)\n",
    "\n",
    "    \n",
    "for discretize_meth in DISCRETIZATION_TECHNIQUES:\n",
    "    for _ in range(100):\n",
    "        # print(discretize_meth)\n",
    "        model = init_model_with_params(discretize_meth, true_model, X, n=n)\n",
    "        Xd = model.discretize(X, np.array([X.shape[0]]))\n",
    "        Xd_c = model.nodes[:, Xd.reshape(-1)].T\n",
    "        res[discretize_meth].append(true_model.score(Xd_c, np.array([X.shape[0]])))\n",
    "\n",
    "    \"\"\"\n",
    "    Plot emission distribution and nodes\n",
    "    \"\"\"\n",
    "    nodes = pca.transform(model.nodes.T)\n",
    "    \n",
    "\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    for k in range(model.n_components):\n",
    "        plt.contour(XX, YY, np.exp(lls[:, k]).reshape(XX.shape),\n",
    "                    cmap=white_to_color_cmap(sns.xkcd_palette(['grey'])[0]), levels=6)\n",
    "\n",
    "    plt.scatter(nodes[:, 0], nodes[:, 1], marker='x', s=80, color=[colors[i] for i in range(model.no_nodes)])\n",
    "    plt.scatter(X2[:, 0], X2[:, 1], marker='o', s=15, color=[colors[i] for i in Xd.reshape(-1)], alpha=1)\n",
    "    plt.xlabel(\"$x_1$\")\n",
    "    plt.ylabel(\"$x_2$\")\n",
    "    plt.suptitle(\"True distributions, sample and nodes - PCA\", size=16)\n",
    "    if discretize_meth in title_strings.keys():\n",
    "        plt.title(f\"{title_strings[discretize_meth]} {n}\", size=14)\n",
    "    else:\n",
    "        plt.title(f\"{discretize_meth} {n}\", size=14)\n",
    "    plt.savefig(f'chapter4/10d_gaussianHmm_discrete_example_{discretize_meth}.eps', format='eps')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "results = (pd.DataFrame(res).rename(title_strings,  axis=1) * -1).melt(None, None, 'sample', 'value')\n",
    "sns.boxenplot(results, x='value', y='sample')\n",
    "plt.ylabel('')\n",
    "plt.vlines(true_model.score(X)* (-1), -.5, 6.5, colors=['black'], linestyles='--')\n",
    "plt.xlabel('negative log-likelihood')\n",
    "plt.title('Log-likelihood of discretized sequences')\n",
    "plt.xscale('log')\n",
    "plt.tight_layout()\n",
    "plt.savefig('chapter4/10d_gaussianHMM_example.eps', format='eps')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d47b8615c9dcd2d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = (pd.DataFrame(res).rename(title_strings,  axis=1) * -1).melt(None, None, 'sample', 'value')\n",
    "sns.boxenplot(results, x='value', y='sample')\n",
    "plt.ylabel('')\n",
    "plt.vlines(true_model.score(X)* (-1), -.5, 6.5, colors=['black'], linestyles='--')\n",
    "plt.xlabel('negative log-likelihood')\n",
    "plt.title('Log-likelihood of discretized sequences')\n",
    "plt.xscale('log')\n",
    "plt.tight_layout()\n",
    "plt.savefig('chapter4/10d_gaussianHMM_example.eps', format='eps')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b0f9a91b7bf3b70"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "270955f8f9742a8d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "71870237c09a720d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
